---
- hosts: localhost
  gather_facts: no
  connection: local
  roles:
    - pebbles_facts
  tasks:
    - name: fork OpenStack image for VMs
      include_role:
        name: fork_openstack_image
      vars:
        forked_image_name: "{{ image_name }}"
      when: public_image_name is defined

    - name: add public key to OpenStack for {{ cluster_name }}
      openstack.cloud.keypair:
        state: present
        name: "{{ cluster_name }}"
        public_key_file: "/dev/shm/{{ cluster_name }}/id_rsa.pub"

    - name: check if stack has been provisioned already
      shell: openstack stack show {{ cluster_name }}
      register: stack_output
      failed_when: false
      changed_when: false

    - when:
        - stack_output.stderr.find('Stack not found') != -1 or force_heat_stack_update | d() | bool
      block:
        - name: build K3s Heat stack
          register: heat_stack
          openstack.cloud.stack:
            name: "{{ cluster_name }}"
            state: present
            template: "files/k3s-heat-stack.yml"
            wait: yes
            parameters:
              env_name: "{{ cluster_name }}"
              cloud_config: "{{ cloud_config|default({}) }}"
              jump_host_allow_ports: "{{ jump_host_allow_ports }}"
              jump_host_allow_cidrs: "{{ jump_host_allow_cidrs }}"
              api_allow_cidrs: "{{ api_allow_cidrs }}"
              api_allow_ports: "{{ api_allow_ports }}"
              ingress_allow_cidrs: "{{ ingress_allow_cidrs }}"
              ingress_allow_ports: "{{ ingress_allow_ports }}"
              network_dns_servers: "{{ network_dns_servers }}"
              network_cidr: "{{ network_cidr }}"
              network_prefix: "{{ network_prefix }}"
              router: "{{ router }}"
              key_name: "{{ cluster_name }}"
              jump_host_vm_image: "{{ jump_host_vm_image }}"
              jump_host_vm_flavor: "{{ jump_host_vm_flavor }}"
              jump_host_vm_ip: "{{ network_prefix }}.10"
              master_vm_image: "{{ master_vm_image }}"
              master_vm_flavor: "{{ master_vm_flavor }}"
              master_vm_ip: "{{ network_prefix }}.11"
              nfs_vm_image: "{{ nfs_vm_image }}"
              nfs_vm_flavor: "{{ nfs_vm_flavor }}"
              nfs_vm_ip: "{{ network_prefix }}.21"
              compute_node_name_suffix: "node"
              compute_node_count: "{{ compute_node_count|default(0) }}"
              compute_node_image: "{{ compute_node_image }}"
              compute_node_flavor: "{{ compute_node_flavor }}"
              compute_node_ids: "{{ compute_node_ids|default([]) }}"

        - name: associate floating IP with master node
          openstack.cloud.floating_ip:
            server: "{{ cluster_name }}-master"
            floating_ip_address: "{{ master_public_ip }}"
            network: "{{ cluster_name }}-network"

        - name: associate floating IP with first jump host
          openstack.cloud.floating_ip:
            server: "{{ cluster_name }}-jump"
            floating_ip_address: "{{ jump_host_public_ip }}"
            network: "{{ cluster_name }}-network"
          when: jump_host_public_ip is defined

        - name: associate volumes with master node
          openstack.cloud.server_volume:
            server: "{{ cluster_name}}-master"
            state: present
            volume: "{{ item }}"
          with_items:
            - "{{ cluster_name }}-k3slib"
            - "{{ cluster_name }}-backup"
            - "{{ cluster_name }}-images"

        - name: associate nfs volume
          openstack.cloud.server_volume:
            server: "{{ cluster_name}}-nfs"
            state: present
            volume: "{{ cluster_name}}-nfs"

        # lock servers to prevent accidental operations for production resources
        - name: lock servers
          shell: openstack server lock {{ item }}
          with_items: "{{ groups['all'] }}"
          when: lock_servers | d(false) | bool

      # endblock

- import_playbook: generate_ssh_config.yml

- hosts: localhost
  gather_facts: no
  connection: local
  tasks:
    - name: wait for connectivity on port 22 on the jump_host
      wait_for:
        host: "{{ jump_host_public_ip }}"
        port: 22
        search_regex: "OpenSSH"
        delay: 5
        timeout: 900

    - name: wait for SSH to work
      shell: >
        ssh {{ jump_host_public_ip }}
        'echo success'
      register: result
      until: result.stdout.find('success') != -1
      retries: 30
      delay: 5
      changed_when: false

- name: install nmap-ncat on bastion if need be
  hosts: jump_host
  gather_facts: no
  become: yes
  tasks:
    - name: Install nmap-ncat
      yum:
        name: nmap-ncat
        state: present

- name: Lock packages
  become: yes
  gather_facts: no
  hosts:
    - masters
    - nodes
    - nfs
  roles:
    - pebbles_facts
  tasks:
    - name: install dnf versionlock plugin
      dnf:
        name: dnf-command(versionlock)
        state: present

    - name: versionlock packages
      blockinfile:
        dest: /etc/dnf/plugins/versionlock.list
        block: |
          {% for package in versionlock_packages|d([]) %}
          {{ package }}          
          {% endfor %}
        create: yes
        mode: '0644'

- name: Package updates for new VMs
  hosts:
    - masters
    - nodes
    - nfs
  roles:
    - pebbles_facts
    - installation_status
  tasks:
    - name: disable auto-updates on Pouta
      file:
        name: /etc/cron.daily/automatic_updates
        state: absent
      become: true

    - name: update OS packages
      dnf:
        name: '*'
        state: latest
      register: _os_packages_updated
      become: true
      when:
        - server_update_and_reboot|default(false)|bool
        - not pb_installed

    - when: _os_packages_updated.changed or server_update_force_reboot|default(false)|bool
      block:
        - name: reboot hosts
          shell: ( /bin/sleep 5 ; shutdown -r now "Ansible triggered reboot" ) &
          async: 30
          poll: 0
          ignore_errors: true
          when: >
          become: true

        - name: wait for hosts to go down
          wait_for:
            state: stopped
            host: "{{ ansible_ssh_host }}"
            port: 22
            timeout: 300
          delegate_to: "{{ hostvars[cluster_name + '-jump']['ansible_ssh_host'] }}"

        - name: wait for connectivity on port 22 on hosts
          shell: ssh -o ControlMaster=no {{ ansible_ssh_host }} 'echo success'
          register: result
          until: result.stdout.find('success') != -1
          retries: 30
          delay: 10
          changed_when: false
          delegate_to: localhost
      #endblock
