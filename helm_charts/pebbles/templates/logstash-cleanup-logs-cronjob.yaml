---
{{- if .Values.logstashVolumeSize }}
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: logstash-log-cleanup
spec:
  schedule: "{{ .Values.backup.logsBackupSchedule }}"
  successfulJobsHistoryLimit: 1
  failedJobsHistoryLimit: 1
  concurrencyPolicy: Forbid
  startingDeadlineSeconds: 600
  jobTemplate:
    spec:
      backoffLimit: 0
      template:
        metadata:
          labels:
            keyval: logstash-val
        spec:
          restartPolicy: Never
          containers:
            - name: logstash-cleanup
              image: {{ .Values.imagePrefix }}{{ .Values.backup.jobImage }}
              imagePullPolicy: {{ .Values.backup.jobImagePullPolicy }}
              command:
                - /bin/bash
                - -c
                - |
                  # bail out on any error
                  set -e

                  # list the files created/modified older than 31 days, tar and encrypt
                  log_files=$(find /data/opt/log/ -type f -mtime +31)

                  if [[ $log_files ]]; then
                     start_ts=$(date -Is -d "$(date -Is) - 31 days")
                     LOGSTASH_BACKUP_DIR=/opt/log/{{ .Values.backup.name }}
                     LOGSTASH_BACKUP_FILE="${LOGSTASH_BACKUP_DIR}/logs-backup-$start_ts"
                     # create backup directory
                     mkdir -p ${LOGSTASH_BACKUP_DIR}
                     tar cvf ${LOGSTASH_BACKUP_FILE}.tar.gz $log_files

                     echo "import public key and set trust"
                     echo "$ENCRYPT_PUBLIC_KEY"  | gpg --batch --no-tty --import
                     echo -e 'trust\n5\ny\n'  | gpg --batch --no-tty --command-fd 0 --edit-key backup
                     gpg --encrypt --batch --no-tty --recipient backup --compress-level 9 ${LOGSTASH_BACKUP_FILE}.tar.gz

                     # remove the unencrypted files
                     rm -rf ${LOGSTASH_BACKUP_FILE}.tar.gz

                     echo "synchronizing to object storage"
                     s3cmd -c /run/secret/s3cfg sync  \
                        ${LOGSTASH_BACKUP_DIR} s3://{{ .Values.backup.s3LogsBucketName }}

                     # importing a private key and decryption to standard out would be
                     # gpg --batch --no-tty --import
                     # (paste private key followed by ctrl-d)
                     # gpg --pinentry-mode=loopback --batch --passphrase=PASSPHRASE <  ${BACKUP_FILE}
                     # To output decrypted contents in file
                     # gpg --batch --passphrase=PASSPHRASE --output <filename> --decrypt **.tar.gz.gpg

                     # clean up the files older than 31 days
                     rm $log_files
                  else
                    echo "nothing to do"
                  fi

              env:
                - name: ENCRYPT_PUBLIC_KEY
                  valueFrom:
                    secretKeyRef:
                      name: backup-secret
                      key: encrypt-public-key
              volumeMounts:
                - name: data
                  mountPath: /data
                - name: logstash-backup-secret
                  mountPath: /run/secret/s3cfg
                  subPath: s3cfg
                - name: tarball-data
                  mountPath: /opt/log

          volumes:
            - name: data
              persistentVolumeClaim:
                claimName: logstash
            - name: logstash-backup-secret
              secret:
                secretName: backup-secret
            - name: tarball-data
              emptyDir: {}

{{- end }}

